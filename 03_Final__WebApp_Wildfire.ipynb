{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananya-ayasi/2022_IBM_Code_Challenge_Wildfire-Detection-and-Burn-Severity-Analysis/blob/main/03_Final__WebApp_Wildfire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWnovZMyF33U"
      },
      "source": [
        "**This notebook covers the creation of a web application to detect fire in uploaded images.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wvj3NqYoQJV",
        "outputId": "661c2499-6b41-443a-f48c-800402b2a334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wCZmk-E_nnjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9ea24a-8c31-4d9e-d189-7f2d7db1c325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 10.1 MB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 34.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 37.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 47.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 29.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 43.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 428 kB 50.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 40.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 793 kB 39.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 381 kB 43.7 MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.13.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.33.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JE2EF4DGDVx"
      },
      "source": [
        "A Python script has to be written separately in order to host it as a web application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAv-fW6xntJB",
        "outputId": "f51a07a5-b598-4490-ae79-1639d544c63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import streamlit as st\n",
        "import PIL\n",
        "import cv2\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from keras.preprocessing import image\n",
        "from keras.models import load_model\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from base64 import b64decode\n",
        "from tensorflow import keras\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "activities = [\"About\",\"Upload Image\",\"Live Detection\",\"Burn Severity Analysis\"]\n",
        "choice = st.sidebar.selectbox(\"Select Activty\",activities)\n",
        "\n",
        "if choice=='About':\n",
        "  st.title(\"Wildfire Detection and Burn Severity Analysis Using UAV and Satellite Imagery\")\n",
        "\n",
        "  video1 = open(\"/content/drive/MyDrive/IBM/IBM GTSP Final.mp4\", \"rb\") \n",
        "  st.video(video1)\n",
        "\n",
        "  st.subheader('Introduction')\n",
        "  st.write(\"\"\"Climate change has been a key factor in increasing the risk and extent of wildfires. \n",
        "  Timing is highly crucial in detecting wildfires and in following sufficient mitigation steps. \n",
        "  Hence, UAVs and satellites can be used in hand with artificial intelligence and image processing \n",
        "  to alert the stakeholders including the forest department, fire department and disaster management units.\"\"\")\n",
        "\n",
        "  img = Image.open(\"/content/drive/MyDrive/IBM/IBM Clip Art.jpg\")\n",
        "  st.image(img)\n",
        "\n",
        "  st.subheader(\"Wildfire Detection\")\n",
        "  st.write(\"\"\"The user can choose the 'Upload Image' option to upload an image from their system.\n",
        "    The web application will try to predict correctly if fire can be detected in the image. \n",
        "    The web application uses a CNN model that was trained on UAV imagery of wildfires for this project.\"\"\")\n",
        "  \n",
        "  st.subheader(\"Live Detection\")\n",
        "  st.write(\"\"\"In the actual scenario, the system will be using UAVs to surveil the perimeters of the forest. \n",
        "  However, due to limitations in time, it was not possible to access an actual UAV for live detection. Hence, we have chosen a feature wherein \n",
        "  the user can use their webcam to capture images and test whether fire is present in the image.\"\"\")\n",
        "\n",
        "  st.subheader(\"Burn Severity Analysis\")\n",
        "  st.write(\"\"\"Burn Severity describes how fire intensity affects functioning of an ecosystem in the area that has been burnt. \n",
        "  Since burn severity may vary based on the specific ecosystem within which the fire has occurred, there is currently no unambiguous \n",
        "  quantifier to objectively map burn severity. Notwithstanding this, two common indices have been proposed and used to detect and assess burn severity from remote-sensing imagery.\"\"\")\n",
        "\n",
        "elif choice=='Upload Image':\n",
        "  @st.cache(allow_output_mutation=True) #to run the following function and store the result in a local cache.\n",
        "  def load_model():\n",
        "    model=tf.keras.models.load_model('/content/drive/MyDrive/IBM/classifier.h5')\n",
        "    return model\n",
        "  with st.spinner('Model is being loaded..'):\n",
        "    model=load_model()\n",
        "\n",
        "  st.title(\"Wildfire Detection using UAV Imagery\")\n",
        "  \n",
        "\n",
        "  file = st.file_uploader(\"Please upload an image\", \n",
        "                          type=[\"jpg\", \"png\"])\n",
        "\n",
        "\n",
        "  st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "\n",
        "  def predict(img_path, model):\n",
        "    size = (64,64)    \n",
        "    image = ImageOps.fit(img_path, size, Image.ANTIALIAS) #to resize the image by avoiding visual defects\n",
        "    image = np.asarray(image)\n",
        "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #convert image from on colour space to another (Several image processing libraries have different pixel orderings.)\n",
        "            \n",
        "    img_reshape = img[np.newaxis,...]\n",
        "\n",
        "    result = model.predict(img_reshape)\n",
        "    \n",
        "    if result[0][0] == 1:\n",
        "        prediction = 'notfire'\n",
        "        return False\n",
        "    else:\n",
        "        prediction = 'fire'\n",
        "        return True\n",
        "\n",
        "\n",
        "  if file is None:\n",
        "    st.text(\"Please upload an image file\")\n",
        "  else:\n",
        "    image = Image.open(file)\n",
        "    st.image(image, use_column_width=True)\n",
        "    predictions = predict(image, model)\n",
        "    #score = tf.nn.softmax(predictions[0])\n",
        "    st.write(predictions)\n",
        "    #st.write(score)\n",
        "    if predictions==True:\n",
        "      st.write(\"\"\"\n",
        "         ## Fire Detected\n",
        "         \"\"\"\n",
        "         )\n",
        "      \n",
        "    else:\n",
        "      st.write(\"\"\"\n",
        "         ## Fire Not Detected\n",
        "         \"\"\"\n",
        "         )\n",
        "\n",
        "elif choice=='Live Detection':\n",
        "  @st.cache(allow_output_mutation=True)\n",
        "  def load_model():\n",
        "    model=tf.keras.models.load_model('/content/drive/MyDrive/IBM/classifier.h5')\n",
        "    return model\n",
        "  with st.spinner('Model is being loaded..'):\n",
        "    model=load_model()\n",
        "  def predict(img_path, model):\n",
        "    size = (64,64)    \n",
        "    image = ImageOps.fit(img_path, size, Image.ANTIALIAS)\n",
        "    image = np.asarray(image)\n",
        "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "    img_reshape = img[np.newaxis,...]\n",
        "\n",
        "    result = model.predict(img_reshape)\n",
        "    \n",
        "    if result[0][0] == 1:\n",
        "        prediction = 'notfire'\n",
        "        return False\n",
        "    else:\n",
        "        prediction = 'fire'\n",
        "        return True\n",
        "  \n",
        "\n",
        "    \n",
        "\n",
        "  st.title(\"Live Detection\")\n",
        "\n",
        "  \n",
        "\n",
        "  picture = st.camera_input(\"Take a picture\")\n",
        "\n",
        "  if picture:\n",
        "    st.image(picture)\n",
        "\n",
        "  image = Image.open(picture)\n",
        "  \n",
        "  predictions = predict(image, model)\n",
        "  st.write(predictions)\n",
        "  if predictions==True:\n",
        "    st.write(\"\"\"\n",
        "         ## Fire Detected\n",
        "         \"\"\"\n",
        "         )\n",
        "      \n",
        "  else:\n",
        "    st.write(\"\"\"\n",
        "         ## Fire Not Detected\n",
        "         \"\"\"\n",
        "         )\n",
        "    \n",
        "elif choice=='Burn Severity Analysis':\n",
        "  st.title(\"Burn Severity Analysis\")\n",
        "  img = Image.open(\"/content/drive/MyDrive/IBM/SR-NBR.jpeg\")\n",
        "  \n",
        "\n",
        "  st.write(\"\"\"Multiple space agencies across the globe including the ESA (Europe), NASA (United States), CNSA (China), JAXA (Japan) and Roscosmos (Russia) \n",
        "  have begun to launch multiple earth-observation satellites from as early as 1957.Of particular interest is a pair of sun-synchronous satellites, known collectively as Sentinel-2. \n",
        "  Sentinel 2 was launched with the aim to monitor variability in land surface conditions with a relatively short revisit period. Sentinel-2 carries a multi-spectral imaging instrument (or MSI), \n",
        "  which is able to passively record 13 spectral bands at 4096 brightness levels. It can 'see' multiple frequencies of radiation, including the visible Red, Green and Blue frequencies. \n",
        "  This enables Sentinel-2 (and other MSI orbiting platforms) to observe earth-based phenomena at a potentially more discerning level than typical RGB measurements. \n",
        "  Moreover, combinations of these bands have been used to extract and classify land-cover using the unique reflectance characteristics of water, types of earth, concrete, etc.\"\"\")\n",
        "\n",
        "  st.subheader(\"Normalized Burn Ratio\")\n",
        "  st.write(\"\"\"Normalized Burn Ratio\n",
        "  The Normalized Burn Ratio (NBR) is an index that uses the differences in the way healthy green vegetation and burnt vegetation reflect light to find burnt area. \n",
        "  It is calculated using the following Sentinel-2 bands: Near Infrared/Band 8 and Shortwave Infrared/Band 12. \n",
        "  NBR returns values between -1 and 1. Healthy green vegetation will have a high NBR value while burnt vegetation will have a low value. \n",
        "  Areas of dry, brown vegetation or bare soil will also return lower NBR values than green vegetation.\"\"\")\n",
        "  \n",
        "  st.subheader(\"Delta Normalized Burn Ratio\")\n",
        "  st.write(\"\"\"Change in Normalized Burn Ratio - also called Delta Normalized Burn Ratio (dNBR) - \n",
        "  is calculated by subtracting the post-fire NBR value from the baseline NBR value as defined in this equation:\"\"\")\n",
        "\n",
        "  st.write(\"\"\"dNBR=NBRbaseline−NBRpost fire\"\"\")\n",
        "\n",
        "  st.write(\"\"\"The dNBR value can be more useful than the NBR alone to determine what is burnt as it shows change from the baseline state. \n",
        "  A burnt area will have a positive dNBR value while an unburnt area will have a negative dNBR value or a value close to zero.\n",
        "  dNBR can also be used to describe burn severity. A higher severity fire will burn more vegetation, resulting in a higher dNBR.\"\"\")\n",
        "\n",
        "  st.image(img)\n",
        "\n",
        "\n",
        "  st.write(\"\"\"The burned zones underwent a significant increase in LST- Land Surface Temperature after fire. Statistically significant differences have been detected \n",
        "    between the LST within regions of burn severity categories. More substantial changes in LST are observed in zones of greater fire severity, \n",
        "    which can be explained by the lower emissivity of combustion products found in the burned area and changes in the energy balance related to vegetation removal.\"\"\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mBFnF0KyAkR",
        "outputId": "3600e822-d428-4db0-c804-fdf6e7e4320b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-06 09:04:41.609 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.738s\n",
            "your url is: https://good-geckos-peel-34-71-2-111.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.71.2.111:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2022-05-06 09:07:08.570149: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-05-06 09:08:11.412 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2847, in open\n",
            "    fp.seek(0)\n",
            "AttributeError: 'NoneType' object has no attribute 'seek'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 475, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 148, in <module>\n",
            "    image = Image.open(picture)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2849, in open\n",
            "    fp = io.BytesIO(fp.read())\n",
            "AttributeError: 'NoneType' object has no attribute 'read'\n",
            "\n",
            "2022-05-06 09:08:44.336 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2847, in open\n",
            "    fp.seek(0)\n",
            "AttributeError: 'NoneType' object has no attribute 'seek'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 475, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 148, in <module>\n",
            "    image = Image.open(picture)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2849, in open\n",
            "    fp = io.BytesIO(fp.read())\n",
            "AttributeError: 'NoneType' object has no attribute 'read'\n",
            "\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "03_Final_ WebApp Wildfire.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNUQUE4N3cmvtbMw4wgGXpd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}